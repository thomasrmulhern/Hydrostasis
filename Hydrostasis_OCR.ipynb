{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Text from Scanned PDF using Pytesseract & Open CV\n",
    "\n",
    "### We are going to extract table data from pdfs whose data is organized in one of three patterns. \n",
    "\n",
    "### After extracting the data from each pdf, we'll transform it and join it with data from other pdfs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strike>First Plan:\n",
    "1. Convert PDFs to images\n",
    "2. Manually collect Regions Of Interest (ROIs) for each protocol \n",
    "3. Use image ROI's to crop images\n",
    "4. Take cropped image and convert to table data or text\n",
    "5. ?\n",
    "\n",
    "Second Plan (1.0):\n",
    "1. Convert PDFs to images~\n",
    "2. Manually get coordinates for slicing with GIMP\n",
    "3. Get cropped images for all pdfs for each type of protocol\n",
    "</strike>\n",
    "\n",
    "Third Plan (1.0):\n",
    "1. Convert PDFs to images\n",
    "2. Figure out how to get appropriately cropped images for each \n",
    "3. Crop all images\n",
    "4. Convert to text or table data\n",
    "5. Convert table data to Dataframe\n",
    "6. Union Urin data \n",
    "7. Delete \"typical ranges\" column, pivot data, and wrangle\n",
    "8. Join dataframes on datetime\n",
    "9. Create columns for calculated fields\n",
    "10. Visualize in Tableau\n",
    "11. Clean, wrangle, and join other data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install necessary packages\n",
    "\n",
    "# !pip install pdf2image opencv-python Pillow pytesseract\n",
    "\n",
    "# # use this command to install poppler (on mac you can also use 'brew install poppler')\n",
    "# !conda install -c conda-forge poppler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up and sort the pdfs\n",
    "\n",
    "The strategy is to clean the pdf file names in a specified directory by replacing spaces with underscores and sorting them into lists by protocol. There is a functionto store the full path to each file to make them easier to access, and a function to get just the filename to make them easier to breakdown in dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out how to clean up the file names\n",
    "# TODO: check for pdf directory in directory, if it doesn't exist, make one\n",
    "# TODO: Move pdfs to pdf directory as jpgs are created\n",
    "import os\n",
    "from re import search\n",
    "\n",
    "def cleansort_file_paths(directory_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input a directory path string and output three lists, one for each protocol, \n",
    "    containing the full path of each file which has been separated by protocol and cleaned.\n",
    "  \n",
    "    Parameters:\n",
    "    directory_path (string): Path to directory containing protocol pdfs\n",
    "  \n",
    "    Returns:\n",
    "    cbc (list) : list containing UCSD-..._Osmo file paths\n",
    "    osmolality (list) : list containing UCSD-..._Urin file paths\n",
    "    urinalysis (list) : list containing UCSD-..._CBC file paths\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    cbc = []\n",
    "    osmolality = []\n",
    "    urinalysis = []\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if search(\"UCSD-..._Osmo\", filename):\n",
    "            new_name = filename.replace(\" \",\"_\")\n",
    "            if filename != new_name:\n",
    "                os.rename(filename,new_name)\n",
    "            if new_name not in osmolality:\n",
    "                osmolality.append(str(directory_path +'/'+new_name))\n",
    "                \n",
    "        elif search(\"UCSD-..._Urin\", filename):\n",
    "            new_name = filename.replace(\" \",\"_\")\n",
    "            if filename != new_name:\n",
    "                os.rename(filename,new_name)\n",
    "            if new_name not in urinalysis:\n",
    "                urinalysis.append(str(directory_path +'/'+new_name))\n",
    "                    \n",
    "        elif search(\"UCSD-..._CBC\", filename):\n",
    "            new_name = filename.replace(\" \",\"_\")\n",
    "            if filename != new_name:\n",
    "                os.rename(filename,new_name)\n",
    "            if new_name not in cbc:\n",
    "                cbc.append(str(directory_path +'/'+new_name))\n",
    "       \n",
    "    return cbc, osmolality, urinalysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from re import search\n",
    "\n",
    "def cleansort_file_names(directory_path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input a directory path string and output three lists, one for each protocol, \n",
    "    containing the full path of each file which has been separated by protocol and cleaned.\n",
    "  \n",
    "    Parameters:\n",
    "    directory_path (string): Path to directory containing protocol pdfs\n",
    "  \n",
    "    Returns:\n",
    "    cbc (list) : list containing UCSD-..._Osmo file names\n",
    "    osmolality (list) : list containing UCSD-..._Urin file names\n",
    "    urinalysis (list) : list containing UCSD-..._CBC file names\n",
    "    all_names (list) : list containing all file names\n",
    "    \"\"\"\n",
    "        \n",
    "    \n",
    "    cbc = []\n",
    "    osmolality = []\n",
    "    urinalysis = []\n",
    "    all_names = []\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        print(filename)\n",
    "        if search(\"UCSD-..._Osmo\", filename):\n",
    "            new_name = filename.replace(\" \",\"_\")\n",
    "            if filename != new_name:\n",
    "                filename = f'{directory_path}{filename}'\n",
    "                os.rename(filename,new_name)\n",
    "            if new_name not in osmolality:\n",
    "                osmolality.append(str(new_name))\n",
    "            if new_name not in all_names:\n",
    "                all_names.append(str(new_name))\n",
    "                \n",
    "        elif search(\"UCSD-..._Urin\", filename):\n",
    "            new_name = filename.replace(\" \",\"_\")\n",
    "            if filename != new_name:\n",
    "                filename = f'{directory_path}{filename}'\n",
    "                os.rename(filename,new_name)\n",
    "            if new_name not in urinalysis:\n",
    "                 urinalysis.append(str(new_name))\n",
    "            if new_name not in all_names:\n",
    "                all_names.append(str(new_name))\n",
    "                    \n",
    "        elif search(\"UCSD-..._CBC\", filename):\n",
    "            new_name = filename.replace(\" \",\"_\")\n",
    "            if filename != new_name:\n",
    "                os.rename(filename,new_name)\n",
    "            if new_name not in cbc:\n",
    "                cbc.append(str(new_name))\n",
    "            if new_name not in all_names:\n",
    "                all_names.append(str(new_name))\n",
    "\n",
    "    return cbc, osmolality, urinalysis, all_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The intention is that you could point the directory_path variable at any local directory containing the pdf \n",
    "# files and the rest of the notebook would be robust enough to run on any OSX system\n",
    "\n",
    "directory_path = '/Users/thomasmulhern/dt/OG_UCSD-001_Hydration_Visit 2_26APR2022_copy/'\n",
    "filepath = directory_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc_paths, osmolality_paths, urinalysis_paths = cleansort_file_paths(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc_names, osmolality_names, urinalysis_names, all_names = cleansort_file_names(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample From Each List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cbc_paths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osmolality_paths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urinalysis_paths[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbc_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "osmolality_names[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urinalysis_names[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Data From File Names Into DataFrame\n",
    "Take each filename from each protocol list and extract the different parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cols = ['filename','partner','patient','protocol','date','time']\n",
    "data = (None,None,None,None,None,None)\n",
    "\n",
    "protocol_data = pd.DataFrame(columns = cols)\n",
    "\n",
    "protocol_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(protocol_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_and_append_data_to_dataframe(list_of_file_names, df_to_append):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input a list of filenames, and the string will be split into filename, partner, patient,\n",
    "    protocol, date, time; those splits will be appended to the dataframe given as an input. \n",
    "    If those are not the column names in the DataFrame, this function will break.\n",
    "    \n",
    "    If the naming convention of the files changes, this function will break.\n",
    "  \n",
    "    Parameters:\n",
    "    list_of_file_names () \n",
    "    df_to_append ()\n",
    "    directory_path (string): Path to directory containing protocol pdfs\n",
    "  \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in list_of_file_names:\n",
    "        if i not in df_to_append['filename']:\n",
    "            split_list = i.split('_')\n",
    "            filename = i\n",
    "            hospital_patient_list = split_list[0].split('-')\n",
    "            partner = hospital_patient_list[0]\n",
    "            patient = hospital_patient_list[1]\n",
    "            protocol = split_list[1]\n",
    "            date = split_list[2]\n",
    "            time = split_list[4]\n",
    "            row = {'filename':filename, 'partner':partner, 'patient':patient, 'protocol':protocol,\n",
    "                   'date':date, 'time':time}\n",
    "            df_to_append = df_to_append.append(row, ignore_index=True)\n",
    "    return df_to_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_data = split_and_append_data_to_dataframe(all_names, protocol_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the PDFs to JPGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pdf to a jpg\n",
    "\n",
    "import os, shutil\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "def convert_pdf_to_jpg(directory, file):\n",
    "    \"\"\"\n",
    "    Loop over a directory, using the path and iterator as inputs.\n",
    "    \n",
    "    If the file is a pdf, convert it to jpg.\n",
    "    \n",
    "    It's unclear how this will react when there are other filetypes besides .pdf in the directory.\n",
    "  \n",
    "    Parameters:\n",
    "    directory (string) - directory path\n",
    "    file (string) - file name\n",
    "  \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    pdf = f\"{directory}{file}\"\n",
    "    pages_in_pdf = convert_from_path(pdf, 350) #might need to tweak number depending on size of the image\n",
    "    i = 1\n",
    "    for page in pages_in_pdf:\n",
    "        image_name = f\"{pdf}\" + str(i) + \".jpg\" \n",
    "        page.save(image_name, \"JPEG\")\n",
    "        i = i+1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_pdfs(directory, file):\n",
    "    \"\"\"\n",
    "    Loop over a directory, using the path and iterator as inputs.\n",
    "    \n",
    "    Check if there is a pdf folder, and if not, create it.\n",
    "    \n",
    "    Move all pdf files to pdf directory so there are only .jpegs.\n",
    "      \n",
    "    Parameters:\n",
    "    directory (string) - directory path\n",
    "    file (string) - file name\n",
    "  \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    new_dir = f'{directory}pdfs/'\n",
    "    \n",
    "    # check if directory exists or not yet\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.makedirs(new_dir)\n",
    "\n",
    "    if os.path.exists(new_dir):\n",
    "        file_path = new_dir + file\n",
    "        print(f'file_path: {file_path}')\n",
    "        \n",
    "        # move files into created directory\n",
    "        shutil.move(directory+file, file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pdf files to jpg\n",
    "for f in os.listdir(filepath):\n",
    "#     print(f)\n",
    "    if f[-4:] == '.pdf':\n",
    "        convert_pdf_to_jpg(filepath, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pdf folder if it doesn't already exist, and move pdfs to pdf folder\n",
    "\n",
    "for f in os.listdir(filepath):\n",
    "    if f[-4:] == '.pdf':\n",
    "        move_pdfs(filepath, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now that we have our images ready to work with, it is time to sort them by protocol and other differentiators and crop them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the pixel placement for key segments using GIMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used gimp to manually find the position of important segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before cropping, clean up the file names and sort the protocols into lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from re import search\n",
    "\n",
    "# Lists of files for each protocol type\n",
    "\n",
    "# Where to look for the files\n",
    "# directory_path = '/Users/thomasmulhern/Desktop/COPY_OG_UCSD-001_Hydration_Visit 2_26APR2022 2'\n",
    "\n",
    "# What the function will search for in the file name\n",
    "osmo_search = \"UCSD-..._Osmo\"\n",
    "urin_search = \"UCSD-..._Urin\"\n",
    "cbc_search = \"UCSD-..._CBC\"\n",
    "\n",
    "cbc = []\n",
    "osmolality = []\n",
    "urinalysis = []\n",
    "def sort_file(directory_path, search_string, protocol_list):\n",
    "    \"\"\"Replace spaces with underscores and rename files before adding them to lists sorted by protocol \"\"\"\n",
    "   \n",
    "\n",
    "    for f in os.listdir(directory_path):\n",
    "        if search(search_string, f):\n",
    "#             r = f.replace(\" \",\"_\")\n",
    "#             # r =\n",
    "#             r = directory_path+'/'+ r\n",
    "#             f = directory_path+'/'+f\n",
    "#             os.rename(f,r)\n",
    "            if f not in protocol_list:\n",
    "                protocol_list.append(str(directory_path +'/'+f))\n",
    "            else:\n",
    "                print(f)\n",
    "    return cbc, osmolality, urinalysis\n",
    "\n",
    "sort_file(directory_path, osmo_search, osmolality)\n",
    "sort_file(directory_path, urin_search, urinalysis)\n",
    "sort_file(directory_path, cbc_search, cbc)\n",
    "\n",
    "# print(os.listdir(directory_path))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking one of the lists to confirm it has full file paths\n",
    "\n",
    "cbc[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF ROBUST, TESTED CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we take the images and crop them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# https://pyimagesearch.com/2021/01/19/crop-image-with-opencv/\n",
    "\n",
    "# Crop images\n",
    "# works when I use the Python parser but not when I use Jupyter notebooks\n",
    "\n",
    "# TODO: Find coordinates for other protocols\n",
    "# TODO: Test the coordinates on all the different files to make sure they still work\n",
    "# TODO: Save images after cropping\n",
    "# TODO: Create funtion to loop through all files in directory\n",
    "# TODO: create crop function\n",
    "\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "# load the input image and display it to our screen\n",
    "\n",
    "# for i in cbc:\n",
    "#     if i[-4:] == '.jpg':\n",
    "#         print(i)\n",
    "\n",
    "image = cv2.imread(cbc[2])\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows() #close the image window\n",
    "\n",
    "\n",
    "\n",
    "# Key coordinates found using GIMP manually\n",
    "\n",
    "cbc_participant = image[94:180, 2284:2626]\n",
    "cbc_protocol = image[524:582, 462:586]\n",
    "cbc_table = image[926:3080, 422:2572]\n",
    "\n",
    "osmo_participant = image[94:180,2284:2626]\n",
    "osmo_protocol = image[514:592,360:678]\n",
    "osmo_table = image[890:1268,410:2604]\n",
    "\n",
    "urin_participant = image[94:180,2288:2626]\n",
    "urin_protocol = image[362:666,510:592]\n",
    "urin_table1 = image[422:2610,906:2132]\n",
    "urin_table2 = image[422:2610,2466:3168]\n",
    "\n",
    "# cv2.imshow(\"Face\", cbc_table)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "\n",
    "# def loop_dir(path):\n",
    "#     pass\n",
    "\n",
    "# def parse_file(filename):\n",
    "#     pass\n",
    "\n",
    "# def crop():\n",
    "#     pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# It turns out, manual selection doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For Urinalysis, some have a \"newer results available banner\" while others do not.\n",
    "- For CBC, some some have a \"newer results available banner\" while others do not, and some have table rows for Imm Gran % and Imm Gran Abs while others do not\n",
    "- For Osmolality, some have a \"newer results available banner\" while others do not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  # This is the code I used to manually find ROIs of important segments\n",
    "\n",
    "# import cv2\n",
    "# im = cv2.imread('/Users/thomasmulhern/Page_1_osmo.jpg')\n",
    "# roi = cv2.selectROI(im)\n",
    "# print(roi)\n",
    "# im_cropped = im[int(roi[1]):int(roi[1]+roi[3]), int(roi[0]):int(roi[0]+roi[2])]\n",
    "# cv2.imshow('Cropped Image', im_cropped)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# These are the ROI's, separated by protocol and formatted in two different ways per protocol\n",
    "\n",
    "# # CBC ROI coordinates\n",
    "\n",
    "# raw_participant_cbc = (2256, 63, 416, 141)\n",
    "# raw_protocol_cbc = (459, 520, 131, 64)\n",
    "# raw_table_cbc = (408, 927, 2215, 2166)\n",
    "# participant_cbc = [(2256, 63), (416, 141)]\n",
    "# protocol_cbc = [(459, 520), (131, 64)]\n",
    "# table_cbc = [(408, 927), (2215, 2166)]\n",
    "\n",
    "# # Urinalysis ROI coordinates\n",
    "# raw_participant_urin = (2268, 90, 364, 100)\n",
    "# raw_protocol_urin = (350, 494, 316, 99)\n",
    "# raw_table_urin1 = (412, 904, 2205, 1228)\n",
    "# raw_table_urin2 = (425, 2457, 2177, 735)\n",
    "# participant_urin = [(2268, 90), (364, 100)]\n",
    "# protocol_urin = [(350, 494), (316, 99)]\n",
    "# table_urin1 = [(412, 904), (2205, 1228)]\n",
    "# table_urin2 = [(425, 2457), (2177, 735)]\n",
    "\n",
    "# # Osmolality ROI coordinates\n",
    "# raw_participant_osmo = (2276, 94, 360, 88)\n",
    "# raw_protocol_osmo = (356, 502, 322, 97)\n",
    "# raw_table_osmo = (416, 905, 2199, 366)\n",
    "# participant_osmo = [(2276, 94), (360, 88)]\n",
    "# protocol_osmo = [(356, 502), (322, 97)]\n",
    "# table_osmo = [(416, 905), (2199, 366)]\n",
    "\n",
    "# # Coordinates grouped by protocol into lists\n",
    "\n",
    "# line_items_coordinates_cbc = [participant_cbc, protocol_cbc, table_cbc] \n",
    "# line_items_coordinates_urin = [participant_urin, protocol_urin, table_urin1,table_urin2] \n",
    "# line_items_coordinates_osmo = [participant_osmo,protocol_osmo, table_osmo]\n",
    "\n",
    "# line_items_coordinates_cbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# cv2.selectROI(raw_table_cbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark the regions of interest in the image and get their respective co-ordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def mark_region(image_path):\n",
    "    \n",
    "    im = cv2.imread(image_path)\n",
    "\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (9,9), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,11,30)\n",
    "\n",
    "    # Dilate to combine adjacent text contours\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "    dilate = cv2.dilate(thresh, kernel, iterations=4)\n",
    "\n",
    "    # Find contours, highlight text areas, and extract ROIs\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    line_items_coordinates = []\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "\n",
    "        if y >= 600 and x <= 1000:\n",
    "            if area > 10000:\n",
    "                image = cv2.rectangle(im, (x,y), (2200, y+h), color=(255,0,255), thickness=3)\n",
    "                line_items_coordinates.append([(x,y), (2200, y+h)])\n",
    "\n",
    "        if y >= 2400 and x<= 2000:\n",
    "            image = cv2.rectangle(im, (x,y), (2200, y+h), color=(255,0,255), thickness=3)\n",
    "            line_items_coordinates.append([(x,y), (2200, y+h)])\n",
    "\n",
    "\n",
    "    return image, line_items_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_image, line_items_coordinates = mark_region('/Users/thomasmulhern/Page_1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_items_coordinates_cbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted_image\n",
    "# line_items_coordinates\n",
    "# line_items_coordinates_cbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply OCR to the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = converted_image\n",
    "\n",
    "# load the original image\n",
    "image = cv2.imread('/Users/thomasmulhern/Page_1.jpg')\n",
    "\n",
    "# get co-ordinates to crop the image (0-86)\n",
    "for i,item in enumerate(line_items_coordinates_cbc):\n",
    "    c = line_items_coordinates[i]\n",
    "\n",
    "    # cropping image img = image[y0:y1, x0:x1]\n",
    "    img = image[c[0][1]:c[1][1], c[0][0]:c[1][0]]    \n",
    "#     print(f\"Image: {img}\")\n",
    "    \n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.set_title(i)\n",
    "    plt.imshow(img)\n",
    "\n",
    "# # convert the image to black and white for better OCR\n",
    "# ret,thresh1 = cv2.threshold(img,120,255,cv2.THRESH_BINARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the image to black and white for better OCR\n",
    "ret,thresh1 = cv2.threshold(img,120,255,cv2.THRESH_BINARY)\n",
    "\n",
    "# pytesseract image to string to get results\n",
    "# text = str(pytesseract.image_to_string(thresh1, config='--psm 6'))\n",
    "# print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_image, line_items_coordinates = mark_region('/Users/thomasmulhern/Page_1temp_distinguisher.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "thresh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pytesseract.image_to_string(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DISCERNING BANNER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check each jpeg from a list to see if a predetermined specific pixel has the predetermined value\n",
    "\n",
    "# If the better choice turns out to be checking all pixels between 0,0 and some cutoff, these are the cutoffs\n",
    "# urinalysis_cutoff = [2972, 912]\n",
    "# osmo_cutoff = [2972, 916]\n",
    "# cbc_cutoff = [2972, 954]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Where we store the file names of the images we will be checking for banners\n",
    "pics = set([])\n",
    "\n",
    "# options for checking files:\n",
    "\n",
    "# list of files\n",
    "# os.listdir('dir_path')\n",
    "\n",
    "# recursive\n",
    "# os.walk('dir_path')\n",
    "\n",
    "# add files to image if they meet the regex criteria for images that we care about\n",
    "# all of the pertinent .jpgs in my local directory end with '1.jpg'\n",
    "\n",
    "for i in os.listdir('/Users/thomasmulhern/dt/COPY_OG_UCSD-001_Hydration_Visit2_26APR2022_2/'):\n",
    "    if re.search('1.jpg$', i):\n",
    "        pics.add(i)\n",
    "\n",
    "# sets to separate files into depending on with or without banner \n",
    "\n",
    "banner =  set([])\n",
    "no_banner = set([])\n",
    "path = '/Users/thomasmulhern/dt/COPY_OG_UCSD-001_Hydration_Visit2_26APR2022_2/'\n",
    "\n",
    "# open each image, load the pixel data, check a specific pixel value against a hardcoded value\n",
    "# pixel and value determined by hand checking images across all protocol types\n",
    "\n",
    "for i in list(pics):\n",
    "    im = Image.open(f\"{path}\"+i)\n",
    "    px = im.load()\n",
    "    if px[700,840] != (r):\n",
    "        no_banner.add(i)\n",
    "#         print(i)\n",
    "    elif px[700,840] == (254, 255, 239):\n",
    "        banner.add(i)\n",
    "    else:\n",
    "        print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(banner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(no_banner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to crop image before HAC\n",
    "def crop(protocol, banner_bool):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Agglomerative Clustering - HAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped image to test\n",
    "left = 420\n",
    "top = 790\n",
    "right = 2618\n",
    "bottom = 2742\n",
    "# og_image_path = \"\"\"/Users/thomasmulhern/dt/COPY_OG_UCSD-001_Hydration_Visit2_26APR2022_2/UCSD-001_CBC_26APR2022_at_1107_Redacted.pdf1.jpg\"\"\"\n",
    "# cropped_image_path = 0\n",
    "im1 = im.crop((left, top, right, bottom))\n",
    " \n",
    "# Shows the image in image viewer\n",
    "im1.save('/Users/thomasmulhern/Desktop/UCSD-001_CBC_26APR2022_at_1107_Redacted.pdf1_CROPPED.jpg')\n",
    "im1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from pytesseract import Output\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-i\", \"--image\", required=True,\n",
    "#     help=\"path to input image to be OCR'd\")\n",
    "# ap.add_argument(\"-o\", \"--output\", required=True,\n",
    "#     help=\"path to output CSV file\")\n",
    "# ap.add_argument(\"-c\", \"--min-conf\", type=int, default=0,\n",
    "#     help=\"minimum confidence value to filter weak text detection\")\n",
    "# ap.add_argument(\"-d\", \"--dist-thresh\", type=float, default=25.0,\n",
    "#     help=\"distance threshold cutoff for clustering\")\n",
    "# ap.add_argument(\"-s\", \"--min-size\", type=int, default=2,\n",
    "#     help=\"minimum cluster size (i.e., # of entries in column)\")\n",
    "# args = vars(ap.parse_args())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/Users/thomasmulhern/Page_1.jpg'\n",
    "im = cv2.imread(image_path)\n",
    "\n",
    "gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (9,9), 0)\n",
    "thresh = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV,11,30)\n",
    "\n",
    "# Dilate to combine adjacent text contours\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9,9))\n",
    "dilate = cv2.dilate(thresh, kernel, iterations=4)\n",
    "\n",
    "# Find contours, highlight text areas, and extract ROIs\n",
    "cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "line_items_coordinates = []\n",
    "for c in cnts:\n",
    "    area = cv2.contourArea(c)\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "\n",
    "    if y >= 600 and x <= 1000:\n",
    "        if area > 10000:\n",
    "            image = cv2.rectangle(im, (x,y), (2200, y+h), color=(255,0,255), thickness=3)\n",
    "            line_items_coordinates.append([(x,y), (2200, y+h)])\n",
    "\n",
    "    if y >= 2400 and x<= 2000:\n",
    "        image = cv2.rectangle(im, (x,y), (2200, y+h), color=(255,0,255), thickness=3)\n",
    "        line_items_coordinates.append([(x,y), (2200, y+h)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(line_items_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# im = cv2.imread('/Users/thomasmulhern/Page_1.jpg')\n",
    "# roi = cv2.selectROI(im)\n",
    "# print(roi)\n",
    "# im_cropped = im[int(roi[1]):int(roi[1]+roi[3]), int(roi[0]):int(roi[0]+roi[2])]\n",
    "# cv2.imshow('Cropped Image', im_cropped)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pdf to jpeg so it can be understood by opencv in the next step\n",
    "# Saves images to local directory\n",
    "# Saves the pdf as a list of 'PIL.PpmImagePlugin.PpmImageFile' objects in a list called pages\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "pdf = r\"/Users/thomasmulhern/Downloads/text_UCSD-001_Hydration Visit 2_26APR2022/x-001_Osmolality_26APR2022 @ 1102_Redacted.pdf\"\n",
    "pages = convert_from_path(pdf, 350)\n",
    "\n",
    "i = 1\n",
    "for page in pages:\n",
    "    image_name = \"Page_\" + str(i) + \"_osmo\" + \".jpg\" \n",
    "    print (type(page))\n",
    "    page.save(image_name, \"JPEG\")\n",
    "    i = i+1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_image_urin, line_items_coordinates_urin = mark_region('/Users/thomasmulhern/Page_1temp_distinguisher.jpg')\n",
    "converted_image_osmo, line_items_coordinates_osmo = mark_region('/Users/thomasmulhern/Page_1temp_distinguisher.jpg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.image_to_string(participant_cbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import packages\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# img = cv2.imread('/Users/thomasmulhern/Page_1.jpg')\n",
    "# print(img.shape) # Print image shape\n",
    "# cv2.imshow(\"original\", img)\n",
    " \n",
    "# # Cropping an image\n",
    "# c = raw_table_cbc\n",
    "# cropped_image = img[c[0][1]:c[1][1], c[0][0]:c[1][0]]\n",
    "# # cropped_image = img[raw_table_cbc[0]:raw_table_cbc[1], raw_table_cbc[2]:raw_table_cbc[3]]\n",
    " \n",
    "# # Display cropped image\n",
    "# cv2.imshow(\"cropped\", cropped_image)\n",
    " \n",
    "# # Save the cropped image\n",
    "# cv2.imwrite(\"Cropped Image.jpg\", cropped_image)\n",
    " \n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--image\", type=str, default=\"/Users/thomasmulhern/Page_1.jpg\", help=\"/Users/thomasmulhern/Page_1.jpg\")\n",
    "args = vars(ap.parse_args())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "osmo_001 = pd.read_csv('/Users/thomasmulhern/dt/CSVs/001_osmo.csv', index_col=False, infer_datetime_format=True)\n",
    "cbc_001 = pd.read_csv('/Users/thomasmulhern/dt/CSVs/001_cbc.csv', index_col=False, infer_datetime_format=True)\n",
    "urin_001 = pd.read_csv('/Users/thomasmulhern/dt/CSVs/001_urin.csv', index_col=False, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urin_001['Component'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f = pd.concat([osmo_001, cbc_001, urin_001], axis=1, keys=\"Component\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.to_csv('/Users/thomasmulhern/dt/UCSD001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
